<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[beforeload]]></title>
  <subtitle><![CDATA[对编程世界充满激情的少年]]></subtitle>
  <link href="http://beforeload.github.io/atom.xml" rel="self"/>
  <link href="http://beforeload.github.io"/>
  <updated>2013-05-28T14:37:05.594Z</updated>
  <id>http://beforeload.github.io/</id>
  <author>
    <name><![CDATA[beforeload]]></name>
    <email><![CDATA[fe.daniel91@gmail.com]]></email>
  </author>
  <generator uri="http://zespia.tw/hexo">Hexo</generator>
  <entry>
    <title type="html"><![CDATA[Common Problems of Recommender Systems]]></title>
    <link href="http://beforeload.github.io/2013/05/27/common-problems-of-recommendation-systems/"/>
    <id>http://beforeload.github.io/2013/05/27/common-problems-of-recommendation-systems/</id>
    <published>2013-05-27T14:14:53.000Z</published>
    <updated>2013-05-27T16:45:59.559Z</updated>
    <content type="html"><![CDATA[<h3>推荐系统的常见问题</h3>
<h4>缺少大数据问题</h4>
<p>Big data是推荐系统最关键的因素之一，对于推荐系统而言，可能最大的问题就是需要大规模的数据才能有效的进行推荐过程。这也毋庸置疑的表示那些拥有典型著名的推荐系统的公司恰恰是那些拥有大量消费者数据的公司：Google, Amazon, Netflix, Last.fm 。</p>
<h4>冷启动问题</h4>
<p>在推荐系统的冷启动问题中，最主要包括两个方面：新用户问题，新资源问题。</p>
<p>(1) 新用户问题</p>
<p>这部分用户在系统中没有资源浏览访问记录，系统无法根据该用户行为数据对其浏览行为进行资源访问的预测和推推荐。</p>
<p>(2) 新资源问题</p>
<p>该部分资源没有用户的访问记录，使得系统在做数据分析时无法将其纳入待处理数据中，进而无法向用户推荐该资源。</p>
<h4>变化数据问题</h4>
<p>推荐系统中的变化数据问题是指推荐系统中常常充斥着老的内容，新的数据资料等很难得到推荐。</p>
<h4>变化喜好问题</h4>
<p>在推荐系统中用户也许怀着不同的目的对于文件资源进行搜索浏览，及用户的喜好是变化跳跃的，系统很难对这种跳跃的喜好类别进行资源数据推荐。</p>
<h4>参考</h4>
<p>(1) <a href="http://readwrite.com/2009/01/28/5_problems_of_recommender_systems">5 Problems of Recommender Systems</a><br>(2) <a href="http://www.resyschina.com/2010/03/five_problems_of_resys.html">推荐系统5大问题</a></p>
]]></content>
    <category scheme="http://beforeload.github.io/tags/Recommendation/" term="Recommendation"/>
    <category scheme="http://beforeload.github.io/tags/Translate/" term="Translate"/>
    <category scheme="http://beforeload.github.io/categories/Recommendation/" term="Recommendation"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[我的一天]]></title>
    <link href="http://beforeload.github.io/2013/05/25/my-daily-life/"/>
    <id>http://beforeload.github.io/2013/05/25/my-daily-life/</id>
    <published>2013-05-25T12:51:15.000Z</published>
    <updated>2013-05-25T15:20:06.135Z</updated>
    <content type="html"><![CDATA[<p>前两天，和两个还在武汉的老同学，还有一个从北京远道而来的老同学会餐，有感于每个人不同的际遇与成。听到别人打趣的说我越来越像一个程序员，傲娇的技术宅，心里反而感觉挺开心。时至周末，思及每天幸福而快乐的生活，遂记下我的一天，以作留恋。</p>
<p>从周一到周五，早上8点半之前起来，这绝对不是说起来很早，只是对比之前每天10点之后起来，这绝对是我今年来做到的最伟大的改变之一了。即使是周末，也在9点左右起来了，真的很不容易，一定要坚持下去。</p>
<a name="more"></a>

<p>最近这段时间，上午都在狂补数据库相关知识，开心的每天练习SQL语句，中午坐在图书馆，恶补数据库相关知识，也许等我研究生毕业，DBA也是一个选择吧。不过周末的时候，我更喜欢泡在实验室，泡杯咖啡，刷刷算法题和ACM题目，或者想一个idea，独自给自己一个hackthon。</p>
<p>下午的时候一般属于精神亢奋期，我的研究方向是分布式计算集群，下午的时候，一边coding，一边看文档是我的常态。当然，偶然也会因为什么问题，一折腾就是一个下午。希望一年之后在分布式计算上也能有所收获吧。</p>
<p>晚自习的时间，通常找本书看个一整章的，静下心来看书是一件很有感觉的事情。最近在看一本书是《Node.js in Action》。而由于女朋友考研，晚上跟她打着电话开心的聊聊天，陪她一起背背单词，真的好幸福。</p>
<p>打过电话睡觉之前，我一般喜欢看看技术博客，刷刷微博，作为一个追求细节的人，每天精读一篇优秀的博文，写点自己的感受。另外把今天学习到的东西做一个总结，这个习惯的养成，主要是有感于最近的两篇blog，<a href="http://blog.jobbole.com/38203/">黄博文：敏捷地写博客</a>和<a href="http://blog.jobbole.com/38258/">《即便没有读者，你也要写博客》</a>。而作为一个技术宅，幸福的在github写着自己的博客。</p>
<p>以上就是我一天的生活。以优秀的工程师为目标，我为自己代言。</p>
]]></content>
    <category scheme="http://beforeload.github.io/tags/Memory/" term="Memory"/>
    <category scheme="http://beforeload.github.io/categories/Memory/" term="Memory"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[Fix Some Ubuntu Problems]]></title>
    <link href="http://beforeload.github.io/2013/05/20/fix-some-problems/"/>
    <id>http://beforeload.github.io/2013/05/20/fix-some-problems/</id>
    <published>2013-05-20T14:10:58.000Z</published>
    <updated>2013-05-25T15:23:31.155Z</updated>
    <content type="html"><![CDATA[<h2>解决的一些Ubuntu 13.04的问题汇总</h2>
<ol>
<li>Fix ASUS Webcam Problem:vertically flip my webcam&#39;s image</li>
</ol>
<p><strong><em>问题描述</em></strong>：华硕电脑摄像头视频图像倒立</p>
<p>解决方法： 在google上搜索了一下 ubuntu camera invert找到几篇解决的博文，步骤如下：</p>
<a name="more"></a>

<p>(1) Install</p>
<pre><code><span class="comment">$echo</span> <span class="literal">-</span><span class="comment">e</span> <span class="comment">"\n#</span> <span class="comment">libv4l</span> <span class="comment">PPA\ndeb</span> <span class="comment">http://ppa</span>.<span class="comment">launchpad</span>.<span class="comment">net/libv4l/ppa/ubuntu</span> <span class="comment">`lsb_release</span> <span class="literal">-</span><span class="comment">c</span> <span class="comment">|</span> <span class="comment">awk</span> <span class="comment">'{print</span> <span class="comment">$2}'`</span> <span class="comment">main"</span> <span class="comment">|</span> <span class="comment">sudo</span> <span class="comment">tee</span> <span class="literal">-</span><span class="comment">a</span> <span class="comment">/etc/apt/sources</span>.<span class="comment">list</span>

<span class="comment">$sudo</span> <span class="comment">apt</span>-<span class="comment">key</span> <span class="comment">adv</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">recv</span>-<span class="comment">keys</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">keyserver</span> <span class="comment">keyserver</span>.<span class="comment">ubuntu</span>.<span class="comment">com</span> <span class="comment">C3FFB4AA</span>

<span class="comment">$sudo</span> <span class="comment">apt</span>-<span class="comment">get</span> <span class="comment">update</span>

<span class="comment">$sudo</span> <span class="comment">apt</span>-<span class="comment">get</span> <span class="comment">install</span> <span class="comment">libv4l</span>-<span class="comment">0
</code></pre>
<p>(2) Start application</p>
<pre><code><span class="variable">$export</span> <span class="constant">LIBV4LCONTROL_FLAGS</span>=<span class="number">3</span> &amp;&amp; cheese
<span class="variable">$export</span> <span class="constant">LIBV4LCONTROL_FLAGS</span>=<span class="number">3</span> &amp;&amp; <span class="constant">LD_PRELOAD</span>=<span class="regexp">/usr/lib</span><span class="regexp">/i386-linux-gnu/libv</span>4l/v4l1compat.so skype
</code></pre>
<p>为了以后不需要输入这么多，建立一个bash
Step 1:</p>
<pre><code>$su<span class="operator"><span class="keyword">do</span> gedit /usr/<span class="keyword">local</span>/bin/skype
</code></pre>
<p>填写下面内容</p>
<pre><code><span class="constant">LD_PRELOAD</span>=<span class="regexp">/usr/lib</span><span class="regexp">/i386-linux-gnu/libv</span>4l/v4l1compat.so /usr/bin/skype
</code></pre>
<p>Step 2:</p>
<pre><code>su<span class="operator"><span class="keyword">do</span> chmod a+x /usr/<span class="keyword">local</span>/bin/skype
</code></pre>
<p><strong><em>注意</em></strong>：
1. v4l1compat.so的位置在Ubuntu 13.04上可能和之前的版本不同，使用locate指令可以先确定一下位置。</p>
<pre><code>$ locate v4l1compat<span class="variable">.so</span>
/usr/lib/i386-linux-gnu/libv4l/v4l1compat<span class="variable">.so</span>
</code></pre>
<p><strong><em>参考</em></strong>：</p>
<p>(1) <a href="http://www.paullabis.com/2010/08/fix-upside-down-or-inverted-webcam-on.html">Fix upside-down or inverted webcam on Ubuntu linux</a></p>
<p>(2)<a href="http://community.linuxmint.com/tutorial/view/219">How to make Webcam compatible with Skype.</a></p>
]]></content>
    <category scheme="http://beforeload.github.io/tags/Ubuntu/" term="Ubuntu"/>
    <category scheme="http://beforeload.github.io/tags/Linux/" term="Linux"/>
    <category scheme="http://beforeload.github.io/categories/Ubuntu/" term="Ubuntu"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[inversion monge quicksort]]></title>
    <link href="http://beforeload.github.io/2013/05/17/inversion-monge-quicksort/"/>
    <id>http://beforeload.github.io/2013/05/17/inversion-monge-quicksort/</id>
    <published>2013-05-17T14:44:25.000Z</published>
    <updated>2013-05-24T13:06:32.663Z</updated>
    <content type="html"><![CDATA[<h2>逆序对，Monge矩阵，快排优化——三数取中划分分析</h2>
<h3>题目</h3>
<ol>
<li>第二章思考题2-4(逆序对)</li>
<li>第四章思考题4-7(Monge矩阵)</li>
<li>第七章思考题7-5(快排的三数取中划分分析)</li>
</ol>
<a name="more"></a>

<h3>2-4 逆序对</h3>
<p>a)</p>
<script src="https://gist.github.com/5599553.js?file=inversion.c"></script>

<p>结果: </p>
<p>(2,3)
(2,8)
(2,6)
(3,8)
(3,6)</p>
<p>b)</p>
<p>从1到n按倒序排列的数组含有最多的逆序对，
个数为(n-1)+(n-2)+...+1 = (n-1 + 1) <em> (n-1)/2 = n </em> (n-1)/2</p>
<p>c)</p>
<p>插入排序的运行时间与输入数组中逆序对的数量之间有怎样的关系?</p>
<p>当数组从小到大排序，插入排序算法复杂度最优为O(n),此时逆序对为0;</p>
<p>当数组从大到小排序，插入排序算法复杂度最坏情况，此时逆序对最多为n * (n-1)/2;</p>
<p>插入排序的过程如下：</p>
<figure class="highlight lang-C"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="code"><pre><span class="keyword">int</span> insert_sort(void)
{
	<span class="keyword">int</span> i, j, key;
	<span class="keyword">for</span> (i = <span class="number">1</span>; i &<span class="keyword">lt</span>; N; i++) {
		key = arr[i];
		j = i;
		<span class="keyword">while</span> (j &<span class="keyword">gt</span>; <span class="number">0</span> && arr[j - <span class="number">1</span>] &<span class="keyword">gt</span>; key) {
			arr[j] = arr[j - <span class="number">1</span>];
			j--;
		}
	}
	<span class="keyword">for</span> (i = <span class="number">0</span>; i &<span class="keyword">lt</span>; N; i++) {
		<span class="keyword">printf</span>(<span class="string">"<span class="variable">%d</span> "</span>, arr[i]);
	}
}
</pre></td></tr></table></figure>

<p>每多一个逆序对存在，就需要多一次比较，运行时间增加。插入排序每次比较后交换元素都是减少一对逆序对，循环本身是对所有的逆序对排序的过程。   </p>
<p>d)
O(nlg(n))修改合并排序，确定n个元素的任意排列中逆序对的数目。</p>
<script src="https://gist.github.com/5599593.js?file=inversion_d.c"></script>


<h3>Monge矩阵</h3>
<p>a)证明：当且仅当矩阵中所有2×2的矩阵都为Monge矩阵时，这个矩阵才为Monge矩阵。</p>
<p>先对行使用归纳法：假设i,k行j，l列矩阵为Monge矩阵，证明i,k+1行，j,l列矩阵为Monge矩阵即可</p>
<p>(1)已知i,k行j,l列为Monge矩阵即A[i,j]+A[k,l] &lt;= A[i,l] + A[k,j]<br>(2)假设A[k,j] + A[k+1,l] &lt;= A[k+1,j] + A[k,l]<br>(3)只需要证明i,k+1行j,l列的矩阵为Monge矩阵，<br>由(1),(2)得A[i,j] + A[k+1,l] &lt;= A[k,j] + A[k+1,l]                </p>
<p>对列用归纳法也是相同步骤，</p>
<p>已知A[i, j]+A[k, n] ≤ A[i, n]+A[k,j]<br>假设<br>A[i, n]+A[k,n+1] ≤ A[i, n+1]+A[k,n]<br>所以A[i, j]+A[k, n+1] ≤ A[i, n+1]+A[k, j]成立。                </p>
<p>行和列都满足归纳法，当<code>A[i,j]+A[i+1,j+1] &lt;= A[i,j+1] + A[i+1,j]</code>时，整个矩阵为Monge矩阵。               </p>
<p><strong>&quot;仅当&quot;</strong>这个条件用反正法可证。           </p>
<p>b) 利用a)的结论：<code>A[i,j] + A[i+1,j+1] &lt;= A[i,j+1]+A[i+1,j]</code>              </p>
<p>很容易得到矩阵第二行第三列到第三行第四列的2×2矩阵不满足条件;<br>所以只需要将第二行第三列的16和第三行第三列的22交换即可。             </p>
<p>c)<br>假设Monge矩阵中存在第x行和第x+1行，<code>f(x) &gt; f(x+1)  (1 &lt;= x &lt; m)</code>               </p>
<p>已知<code>A[x,f(x+1)] + A[x+1, f(x)] &lt;= A[x,f(x)] + A[x+1, f(x+1)]</code>                </p>
<p>又因为             </p>
<p>A[x,f(x)] &lt; A[x, f(x+1)]        (1)<br>A[x+1,f(x+1)] &lt;= A[x+1, f(x)]   (2)</p>
<p>(1) + (2) 得：                 </p>
<p>A[x,f(x+1)] + A[x+1, f(x)] &gt; A[x, f(x)] + A[x+1,f(x+1)]   (3)</p>
<p>根据a)结论，任意2×2矩阵都有</p>
<p>A[i,j] + A[i+1,j+1] &lt;= A[i,j+1]+A[i+1,j]      (4)</p>
<p>(3) 和 (4)矛盾，假设不成立。<br>由此可得：</p>
<p>f(1) &lt;= f(2) &lt;= ... &lt;= f(m)            </p>
<p>d) 已知偶数行最左端最小值f(2), f(4), f(6), ... 
且f(2k) &lt;= f(2k+1) &lt;= f(2(k+1))</p>
<p>奇数行搜索一次，搜索范围为n列，偶数行重复计算两次</p>
<p>奇数行最左端最小值时间复杂度O(m/2+n)=O(m+n)
e)
由d)可得递归式：T(m) = T(m/2) + O(m+n)</p>
<p>递归运算结果：</p>
<p>T(m) = O(nlgm) + O(m+n)<br>     = O(nlgm + m + n)<br>     = O(nlgm + m)              </p>
<h3>快排中三数取中划分分析</h3>
<p><img src="//i.minus.com/i29Ufb20Oolkw.jpg" class="[inversion]">
答案用图片显示，<a href="//i.minus.com/i29Ufb20Oolkw.jpg">图片在这里</a> </p>
<p>参考文章</p>
<ol>
<li><a href="//blog.csdn.net/zhanglei8893/article/details/6266915">“三数取中“划分</a></li>
</ol>
]]></content>
    <category scheme="http://beforeload.github.io/tags/Algorithm/" term="Algorithm"/>
    <category scheme="http://beforeload.github.io/categories/Algorithm/" term="Algorithm"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[Three-points to Understanding Node.js]]></title>
    <link href="http://beforeload.github.io/2013/05/04/three-points-understanding-node.js/"/>
    <id>http://beforeload.github.io/2013/05/04/three-points-understanding-node.js/</id>
    <published>2013-05-03T18:24:52.000Z</published>
    <updated>2013-05-25T15:20:27.915Z</updated>
    <content type="html"><![CDATA[<h2>从三点去理解Node.js</h2>
<p>Node is:  </p>
<ul>
<li>基于JavaScript(Built on JavaScript)</li>
<li>事件驱动和异步(Evented and Asynchronous)</li>
<li>对于数据密集型实时应用(For Data-Intensive Real-Time Applications)</li>
</ul>
<a name="more"></a>

<h3>基于JavaScript</h3>
<p>第一点很好理解，是用JavaScript开发，由谷歌的<a href="https://code.google.com/p/v8/">V8引擎</a>驱动运行。Node使用V8,在服务端运行JavaScript，减少了中间步骤，执行过程中，解释器直接编译成自然机器语言。好处多多：</p>
<ol>
<li>开发者只需要用一种语言就可以开发一套网络应用，减少服务端和客户端开发时所需要的上下文切换，且允许服务端和客户端代码共享(例如重用表单验证，或者游戏的逻辑)。</li>
<li>JSON这种数据格式很性感，它就是自然的JavaScript</li>
<li>JavaScript可以使用多种NoSQL数据库（如：CouchDB/MongoDB），可以和他们无缝连接，非常适合（如：MongoDB shell和查询语言就是JS，CouchDB map/reduce 是JS）。</li>
<li>有很多语言以JavaScript为编译目标<br><a href="https://github.com/jashkenas/coffee-script/wiki/List-of-languages-that-compile-to-JS">List of languages that compile to JS</a></li>
<li>Node使用虚拟引擎V8,并遵守ECMAScript标准。</li>
</ol>
<h3>时间驱动和异步</h3>
<p>第二点，Node.js给服务器端JavaScript提供了一个事件驱动和异步的平台。JavaScript跑在服务端其实和JavaSript跑在客户端在很大程度上是相似的。理解浏览器的怎么运行对于理解Node的运行很重要。两者都是事件驱动（使用的是事件循环）和无阻塞IO处理（如：异步IO）。</p>
<p>未完！</p>
<h3>DIRTy Applications(<strong><em>Data-Intensive Real-Time</em></strong> Applications)</h3>
<h3>推荐资源：</h3>
<ol>
<li>强烈推荐视频<a href="//www.youtube.com/watch?v=Trurfqh_6fQ">Javascript: Your New Overlord</a>, 由Douglas Crockford大神主讲。</li>
</ol>
]]></content>
    <category scheme="http://beforeload.github.io/tags/Node.js/" term="Node.js"/>
    <category scheme="http://beforeload.github.io/tags/JavaScript/" term="JavaScript"/>
    <category scheme="http://beforeload.github.io/categories/Node.js/" term="Node.js"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[Graduation Summary]]></title>
    <link href="http://beforeload.github.io/2013/04/29/graduation-summary/"/>
    <id>http://beforeload.github.io/2013/04/29/graduation-summary/</id>
    <published>2013-04-29T09:19:09.000Z</published>
    <updated>2013-05-25T00:50:02.943Z</updated>
    <content type="html"><![CDATA[<h2>毕业总结</h2>
<h5>写在前面的话</h5>
<p>一直觉得自己很忙，但又说不出来自己忙在哪里，很大程度上都是各种酱油的生活，也许我应该过忙碌的生活，这样就不会想得太纠结，思考得太无聊。幸运的是受到别人总结的启发，自我感觉也算有点经历的人，写下这样的一篇自我总结，就从2012年到现在做一个总结吧。</p>
<a name="more"></a>

<h3>曾经的无奈</h3>
<p>为什么总结选择2012年开始，也许12年之前的生活太过于平庸了吧。不得不说，我的大学是失败的，至少大一大二是失败的，感觉失望，感觉没有什么收获，甚至在颓靡的学风中开始堕落。</p>
<p>这篇总结之前写了一点，这两天看了复旦大学的退学生袁涛的事情后，其实还是有点儿羡慕的，因为同样是学风不好，别人可以激进的去挑战权威，挑战自我，而我却因此而堕落，这是无奈的，至少自我感觉很不好。我删了之前写的草稿，重写了这篇文章。</p>
<h3>一朝醒悟</h3>
<p>人生在关闭一个门之后，会给你打开另一个门。我是幸运的，你可能无法想象堕落黑暗的日子重见光明的喜悦。在大学没有目标的走了两年，幸运的我终于找到自己的方向，因为我对技术的热爱从未改变，也许更准确的表达是对待技术就像对待信仰一般，追求的热情从未消退。</p>
<p>大三找到一个好的实习是件开心的事情，提前体验社会的同时也锻炼了自己。在找实习的过程中，也发现自己存在很多不足之处的，尤其在面试受挫后，体会更加深刻。在见识到同学的成功后，我深刻体会到这样一个道理，惨淡的人生从来不会亲睐有准备的人。面对别人的成功，替别人感到高兴的同时，心里何尝没有一丝对自己的悲哀呀。每次面试的机会都应该好好把握，我感觉与面试官的交流也给自己上了很大的一课，检讨自己的不足，当然也要肯定自己的优点，对于充满挑战的人生，千万不能丧失自信。我觉得我人生的醒悟也是从这个时候开始，收起浮躁，收起颓废，开始人生的征程。</p>
<h3>青春的爱情</h3>
<p>在我决定充满自信的面对人生的挑战，开始新生的这一刻，令我感到惊讶的是，我爱情的萌芽也开始了。2012年，开始了我人生中的初恋，也许正是维系到至今的爱情，让我觉得到现在为止不是那么失败吧。</p>
<p>爱情的力量是伟大的，至少在某一时期，是可以超越一切的。我从没想过我的感情给我带来如此之大的改变，看到我不再逃避的时候，心里还是有点窃喜的。</p>
<h3>实习的收获</h3>
<p>在点评实习，有幸遇到鑫威，寸老师等良师益友，很想亲口对他们说句谢谢，一直回来后没有开口，想来还是挺后悔。从一开始的零基础，一步步的成长，虽然现在还是一无所长，不过至少被师傅领进门了吧。记得在公司的一件开心的事，和寸老师玩LOL，和鑫威打dota，为此老大还特意喊我聊过天，至今想起来还是觉得挺亏欠老大的，当然也不得不提跟亮亮一起玩桌球，跟云华，寸老师一起打乒乓球，还有超哥一起玩桌上足球，实在是开心至极。后来老大为我这样一个实习生离职，还举办了欢送晚餐，实在是感动至极。与人相处，共同进步，这是我在点评第一点重大收获。</p>
<p>在点评，技术氛围是很浓厚的，虽然提倡产品思想，但是团队里还是很多geek的存在。记得刚刚接触Node.js，寸老师让我写一个HTTP Server，没做的时候不知道怎么去做，觉得好难，后来用了express，只写了10行代码，自以为了不起的时候，寸老师给了一个pull request，精简到只要4行代码，当时我就觉得我还有很长的路要走呀。戒骄戒躁，追求完美，这是我在点评学到的第二点重要的收获。</p>
<p>在点评，参加两次举办的hackthon也是收获颇丰的，一两天时间，实现一个堪比在学校一两个月做出来项目，也是我越来越喜欢coding或者说希望成为一个技术专家。用技术实现自己的idea，是一件幸福的事情。小时候看父亲会修自行车，会装玻璃，动手能力一流，我就很羡慕和崇拜。所以现在coding的时候，感觉自己想是在写作品，虽然至今没写出来什么NB的东西，不过总感觉coding的过程，充满了艺术气息。热爱技术，解决问题，这是我在点评收获的第三点吧。</p>
<p>当然还有很多收获，不能一一列举，现在回到学校读研，记下这些也是保留这段美好的回忆吧。</p>
<h3>大四在大学</h3>
<p>实习回来，学校还是当年的学校，刚刚回到大学的时候，我不能适应这样的生活，现在的大学教育是有问题的，很多人也说学校的学风大不如从前。我喜欢忙碌的生活，喜欢去学习，去追求点什么。大学里的悠闲，身边的安逸，与我开始有点格格不入，对大学还有憧憬的人肯定无法想象。其实大学上与不上无关紧要，跳出大学再回来看，我开始明白我的路还是要独自奋斗，知道路在何方，走下去就可以了，找到了人生的追求和理想，也许这就是我大学最大的收获吧。</p>
<h3>收获</h3>
<p>在大学里，培养了一些恶习，比如说拖延症之类的。大学还是很开心的，遇到一群良师益友，很感谢他们给了我很大的帮助。</p>
<p>人生不能没有目标，对待梦想，要想饿狼一样随时保持冲刺的姿态，看到别人的成功，本科阶段就要告一段落了，虽然失败，懊悔挺多，但是，还是学到很多</p>
]]></content>
    <category scheme="http://beforeload.github.io/tags/Memory/" term="Memory"/>
    <category scheme="http://beforeload.github.io/categories/Memory/" term="Memory"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[内容聚合Nodejs的实现]]></title>
    <link href="http://beforeload.github.io/2013/04/28/content-syndication-with-node.js/"/>
    <id>http://beforeload.github.io/2013/04/28/content-syndication-with-node.js/</id>
    <published>2013-04-28T02:16:15.000Z</published>
    <updated>2013-05-27T16:37:32.871Z</updated>
    <content type="html"><![CDATA[<h3>[翻译]Content Syndication with Node.js</h3>
<hr>
<p>原文链接 <a href="http://howtonode.org/content-syndication-with-node">Content Syndication with Node.js</a></p>
<p>对于任何一个想和其他系统信息共享的网站而言，网络聚合是必须的。建议最好去了解一下RSS或者Atom之类的消息来源标准的格式规范，如果不采用一个处理这种格式的模块，生成这样的文本信息会是一件非常麻烦且耗时的工作。非常感谢<a href="https://npmjs.org/">NPM</a>，正由于nodejs的包管理工具的强大之处，自从有了它，再也不用担心生成自己的消息来源会耗费大量时间了。</p>
<a name="more"></a>

<h4>安装feed包</h4>
<p>  在开始之前，进入你的项目文件夹下，安装feed的最新版本</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre><span class="variable">$npm</span> install feed
</pre></td></tr></table></figure>

<h4>建立订阅</h4>
<p>第一步：建立一个Feed(用来接收该信息来源更新的接口)的对象。当我们初始化这个对象的时候，提供我们网络聚合订阅的基本信息（这句话感觉怎么翻译怎么不通顺，我觉得就是根据我们了解的RSS或者Atom之类的格式，结合自己的网站提供相应信息）。如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="code"><pre>// 需求的包
varFeed=require(<span class="string">'feed'</span>);

// 初始化feed对象
var feed =newFeed({
  <span class="method">title:</span>          <span class="string">'My Feed Title'</span>,
  <span class="method">description:</span>    <span class="string">'This is my personnal feed!'</span>,
  <span class="method">link:</span>           <span class="string">'http://example.com/'</span>,
  <span class="method">image:</span>          <span class="string">'http://example.com/logo.png'</span>,
  <span class="method">copyright:</span>      <span class="string">'Copyright © 2013 John Doe. All rights reserved'</span>,

  <span class="method">author:</span>{
    <span class="method">name:</span>       <span class="string">'John Doe'</span>,
    <span class="method">email:</span>      <span class="string">'john.doe@example.com'</span>,
    <span class="method">link:</span>       <span class="string">'https://example.com/john-doe'</span>
  }
});
</pre></td></tr></table></figure>


<p>第二步：你可能希望区分自己的订阅专题。RSS和Atom标准格式都提供了一个或多个分类。当然，添加它们也超级简单：</p>
<p><code>feed.category(&#39;Node.js&#39;);
feed.category(&#39;JavaScript&#39;);</code></p>
<p>第三步：每个订阅都需要至少一个项目。（最好是一个入口）要做到这一点，你必须使用这些功能项目并提供合适的对象。当然，当你正在运行一个内容网站（就像你的博客），很可能发生的情况是你有多个项目。为了填充你的订阅信息，使用一个for循环，如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
</pre></td><td class="code"><pre><span class="function"><span class="title">for</span><span class="params">(var key in posts)</span>{
  <span class="title">feed</span>.<span class="title">item</span><span class="params">(<span class="tuple">{
    title:  posts[key].title,
    link:  posts[key].link,
    description: posts[key].description,
    date: posts[key].date
  }</span>
}
</pre></td></tr></table></figure>


<p>到这一步，生成RSS或者Atom标准的订阅的一切准备都已经OK了，使用下面的render方法</p>
<p><code>var output = feed.render()</code></p>
<p>这是含蓄的方式调用render请求。默认的是，它会渲染成RSS标准的订阅。你也可以使用这种含蓄的方式，选择RSS或者Atom</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
</pre></td><td class="code"><pre><span class="comment">// Rendering a RSS 2.0 valid feed</span>
feed.<span class="keyword">render</span>(<span class="string">'rss-2.0'</span>);

<span class="comment">// Rendering an Atom 1.0 valid feed</span>
feed.<span class="keyword">render</span>(<span class="string">'atom-1.0'</span>);
</pre></td></tr></table></figure>

<p>是的，就是这么简单！</p>
<p>feed结合 Express.js 一起会变得超级简单。告诉你一个使用app.get()方法去路由/rss路径。为了推送你的订阅，像我们之前提到的那样渲染我们的订阅。然后，把Content-type 设置成 text/xml：</p>
<figure class="highlight lang-JavaScript"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
</pre></td><td class="code"><pre>app.get(<span class="string">'/rss'</span>,<span class="keyword">function</span>(req, res){
  <span class="comment">// Initializing feed object</span>
  <span class="keyword">var</span> feed =newFeed({
    title:          <span class="string">'My Feed Title'</span>,
    description:    <span class="string">'This is my personnal feed!'</span>,
    link:           <span class="string">'http://example.com/'</span>,
    image:          <span class="string">'http://example.com/logo.png'</span>,
    copyright:      <span class="string">'Copyright © 2013 John Doe. All rights reserved'</span>,

    author:{
      name:       <span class="string">'John Doe'</span>,
      email:      <span class="string">'john.doe@example.com'</span>,
      link:       <span class="string">'https://example.com/john-doe'</span>
    }
  });

  <span class="comment">// Function requesting the last 5 posts to a database. This is just an</span>
  <span class="comment">// example, use the way you prefer to get your posts.</span>
  Post.findPosts(<span class="keyword">function</span>(posts, err){
    <span class="keyword">if</span>(err)
      res.send(<span class="string">'404 Not found'</span>,<span class="number">404</span>);
    <span class="keyword">else</span>{
      <span class="keyword">for</span>(<span class="keyword">var</span> key <span class="keyword">in</span> posts){
        feed.item({
          title:          posts[key].title,
          link:           posts[key].url,
          description:    posts[key].description,
          date:           posts[key].date
        });
      }
      <span class="comment">// Setting the appropriate Content-Type</span>
      res.set(<span class="string">'Content-Type'</span>,<span class="string">'text/xml'</span>);

      <span class="comment">// Sending the feed as a response</span>
      res.send(feed.render(<span class="string">'rss-2.0'</span>));
    }
  });
});
</pre></td></tr></table></figure>

<h3>总结：</h3>
<p>就这样了，现在人们终于可以从你的nodejs应用中读取订阅你的项目。</p>
<p>译者：其实到这个地方还没有结束，本人在处理这个问题时感觉远远不想大神说的那么easy。有兴趣的最好自己尝试一下。</p>
<p>wrapper —— 包
feed —— 订阅
Feed —— 用来接收该信息来源更新的接口</p>
]]></content>
    <category scheme="http://beforeload.github.io/tags/Translate/" term="Translate"/>
    <category scheme="http://beforeload.github.io/tags/Node.js/" term="Node.js"/>
    <category scheme="http://beforeload.github.io/categories/Node.js/" term="Node.js"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[Collaborative Markov Chain Model]]></title>
    <link href="http://beforeload.github.io/2013/04/22/collaborative-markov-chain-model/"/>
    <id>http://beforeload.github.io/2013/04/22/collaborative-markov-chain-model/</id>
    <published>2013-04-22T13:23:27.000Z</published>
    <updated>2013-05-25T15:25:01.567Z</updated>
    <content type="html"><![CDATA[<h2>理论</h2>
<h3>马尔可夫过程(Markov Process)</h3>
<p>Markov过程是一个满足Markov性(无后效性)的随机过程。
具有马尔可夫性质的随机过程称为<strong>马尔可夫</strong>过程。[1]</p>
<p>最有名的Markov过程是Markov链，但还有其他的过程，如布朗运动，也是Markov过程。</p>
<a name="more"></a>

<h3>马尔可夫性质</h3>
<p><strong>马尔可夫性质</strong>是概率论中的一个概念。当一个随即过程在给定状态及所有过去状态情况下，其未来状态的条件概率分布仅依赖于当前状态；换句话说，在给定现在状态时，它与过去状态（即该过程的历史路径）是条件独立的，那么此随机过程具有<strong>马尔可夫性质</strong>。[2]</p>
<p>过程或（系统）在时刻t0所处的状态为已知的条件下，过程在时刻t&gt;t0所处状态的条件分布，与过程在时刻t0之前所处的状态无关的特性称为马尔可夫性或无后效性。[1]即：已知“现在”过程的情况下，“<em>将来</em>”过程的情况与“<em>过去</em>”的情况无关。</p>
<p>数学上，如果&#39;X(t),t&gt;0&#39;为一个随机过程，则马尔可夫性质就是指</p>
<img src="//upload.wikimedia.org/math/7/a/d/7ad721c51e3fd880f548cbfa67e80832.png" class="[img]">


<p>马尔可夫过程通常称其为<strong>（时间）齐次</strong>，如果满足</p>
<img src="//upload.wikimedia.org/math/1/a/9/1a97955e98197a3ef3212d0cfba0a752.png" class="[img]">

<p>则称为<strong>（时间)非齐次</strong></p>
<h3>马尔可夫链</h3>
<p><strong>定义：</strong></p>
<p>马尔可夫链是随机变量<em>X1,X2,X3...</em>的一个数列。这些变量的范围，即他们所有可能取值的集合，被称为“状态空间”，而Xn的值则是在时间的状态。</p>
<p>已知随机变量Xn是n时刻的状态，如果Xn+1对于过去状态的条件概率分布仅是Xn的一个函数，则</p>
<p><code>P(Xn+1=x|X0,X1,X2,…,Xn)=P(Xn+1=x|Xn), x为过程中的某个状态。</code></p>
<p>时间和状态都是离散的Markov过程称之为Markov链，简记为马氏链。</p>
<h3>马氏链的转移概率(Transition probability)</h3>
<p>在经过一段较长时间的状态转移后，Markov过程会逐渐趋于稳定状态，且与初始状态无关，称为终极状态概率，或平衡状态概率。此时，记终极状态概率向量为X=[x1,x2,…,xn],则有X=Xp,0&lt;=Xi&lt;=1(I=1,2，…,n)，可用于预测Markov过程在未来出现什么趋势的重要信息。目前多应用于统计，生物，地理统计学，人力资源，因特网应用等多个领域。</p>
<h3>Slope one 协同过滤算法</h3>
<p><strong>Slope One</strong> 是一系列应用于 协同过滤的算法的统称。由于它的简洁高效，并拥有不输于其他复杂算法的精确度，因此用它来改进Markov链模型。</p>
<p>简要说明一下，<strong>Slope One</strong>和大多评分算法类似并不适用于类似电子商务中，买家只提供买或者不买这样的二进制数据情况。</p>
<p>Slope One的一系列基于Item-based协同过滤算法，其本质上都是线性回归函数(f(x) = x + c)，好处是减少<strong>过适（过拟合）</strong>。对比于一个项目评分和另一个项目评分的线性回归（f(x) = ax + c），它只需要一半的存储量。也符合<strong><em>奥卡姆剃刀</em></strong>的原理：<strong>若无必要，勿增实体</strong>。</p>
<img src="//upload.wikimedia.org/wikipedia/commons/c/cb/Simplicity_diagram.png">

<ol>
<li>User A 对 Item I 评分为1 对Item J 评分为1.5</li>
<li>User B 对 Item I 评分为2</li>
<li>你认为 User B 会给 Item J 打几分?</li>
<li>Slope One 的答案是：2.5 (1.5-1+2=2.5).</li>
</ol>
<p>对“n”个项目，想要实现 <strong>Slope One</strong>，只需要计算并存储“n”对评分间的平均差值和评价数目即可。</p>
<h3>协同马尔可夫链模型</h3>
<p>使用改变的<strong>Slope One</strong>对数据进行初次协同过滤处理，并在此基础上结合Markov链模型对用户行为进行分析预测。在一个推荐系统中，推荐的准确性很大程度上取决于其基于的数据库的大小，数据量小的情况下，经常会遇到冷启动的问题（Cold boot problem），区别于计算机系统的冷启动（Cold Start），它包括两个方面，一方面是新指用户没有行为数据，无法根据历史行为，预测其兴趣爱好，另一方面是新资源没有访问记录，没有数据分析，无法向用户推荐。</p>
<p>使用协同马尔可夫链模型，可以相对准确的预测用户的兴趣，有效的减少冷启动的问题。</p>
<p>以上是理论部分，简单介绍了协同马尔可夫模型的一些理论依据，下面重点讲解其在用户行为分析中的应用与分析。</p>
<h3>参考文献：</h3>
<ol>
<li><a href="http://wiki.mbalib.com/wiki/马尔可夫过程">马尔可夫过程 - MBA智库百科</a></li>
<li><a href="https://zh.wikipedia.org/wiki/马尔可夫性质">马尔可夫性质- 维基百科，自由的百科全书 - 维基百科- Wikipedia</a></li>
</ol>
]]></content>
    <category scheme="http://beforeload.github.io/tags/Math/" term="Math"/>
    <category scheme="http://beforeload.github.io/categories/Math/" term="Math"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[Inverted Index in Hadoop]]></title>
    <link href="http://beforeload.github.io/2013/04/18/invertedindex-in-hadoop/"/>
    <id>http://beforeload.github.io/2013/04/18/invertedindex-in-hadoop/</id>
    <published>2013-04-18T04:26:32.000Z</published>
    <updated>2013-05-25T15:24:03.891Z</updated>
    <content type="html"><![CDATA[<h2>倒排索引</h2>
<h3>简介:</h3>
<p>倒排索引是文档检索系统中最常用的数据结构，被广泛地应用于全文搜索引擎。它主要是用来存储某个单词(或词组)在一个文档或一组文档中的存储位置的映射，即提供了一种根据内容来查找文档的方式。由于不是更具文档来确定文档包含的内容，而是进行想法的操作，因而成为倒排索引(Inverted Index)。[1]</p>
<a name="more"></a>

<p>我的理解就是找到单词出现的文档的名称，多数情况下为一个列表。</p>
<p>一个单词可能在不同的文件中出现，所以我们需要定义一个权重，表示单词(即搜索的内容)跟文档的<strong><em>相关度</em></strong>。相关度的衡量多数情况下用<strong><em>词频</em></strong>来表示。</p>
<p>更加复杂的算法TF-IDF(Term Frequency-Inverse Document Frequency)统计单词在多少个文档中出现，甚至考虑单词在文档中出现的位置(例如标题处反应这个单词的重要性)。</p>
<p>理论的东西到此结束，下面写一下倒排索引的设计与实现。</p>
<h3>问题分析：</h3>
<p>信息的关键： <strong>单词</strong>，<strong>文档URI</strong>及<strong>词频</strong></p>
<h3>设计：</h3>
<h4>Map过程：</h4>
<p>TextInputFormat: 输入文件处理 -&gt; 文本每行的偏移量及其内容<br><code>&lt;key, value&gt;</code> =&gt;  单词，文档URI和词频<br>两个值对应三个值，需要增加Combine过程进行词频统计。</p>
<p><strong><em>key</em></strong>： <strong>单词:URI</strong> (例如：MapReduce:1.txt)<br><strong><em>value</em></strong>：<strong>词频</strong>，相同单词词频组成列表传递给Combiner过程，实现的功能类似于WordCount      </p>
<h4>Combine过程：</h4>
<p>Combine过程会把相同的key值对应的value值累加<br>Map过程得到的结果为    </p>
<figure class="highlight lang-C"><table><tr><td class="gutter"><pre>1
2
3
4
</pre></td><td class="code"><pre><span class="string">"MapRuduce:file01.txt"</span>  <span class="keyword">list</span>(<span class="number">1</span>)          =&gt;     <span class="string">"MapReduce:file01.txt"</span>  <span class="number">1</span>    
<span class="string">"is:file01.txt"</span>         <span class="keyword">list</span>(<span class="number">1</span>,<span class="number">1</span>)        =&gt;     <span class="string">"is:file01.txt"</span>         <span class="number">2</span>    
<span class="string">"powerful:file01.txt"</span>   <span class="keyword">list</span>(<span class="number">1</span>)          =&gt;     <span class="string">"powerful:file01.txt"</span>   <span class="number">1</span>    
<span class="string">"simple:file01.txt"</span>     <span class="keyword">list</span>(<span class="number">1</span>)          =&gt;     <span class="string">"simple:file01.txt"</span>     <span class="number">1</span>   
</pre></td></tr></table></figure>

<p><strong><em>key</em></strong>： <strong>单词</strong>
<strong><em>value</em></strong>: <strong>URI:词频</strong>(如：1.txt:1)</p>
<p><strong>好处</strong>：可以利用MapReduce框架默认的HashPartitioner类完成Shuffle过程。</p>
<h4>Reduce过程：</h4>
<p>Combiner过程就已经把相同的单词的所有记录发送给同一个Reducer进行处理，Reduce过程就变得很简单，只需要将相同的key和value值组合成倒排索引文件所需的格式即可，剩下的交给MapReducer框架自动完成。</p>
<h4>问题</h4>
<ol>
<li>文件数目;</li>
<li>文件大小;</li>
<li>Reduce过程没有统计词频，有可能会造成词频未统计完全的单词。    </li>
</ol>
<p><strong>备注及解决办法：</strong></p>
<ol>
<li>单个文件不宜过大，具体值与默认HDFS块大小及相关配置有关；</li>
<li>重写InputFormat类将每个文件作为一个split；</li>
<li>执行两次MapReduce，第一次统计词频，第二次MapReduce用于生成倒排索引。</li>
</ol>
<h4>优化思路：</h4>
<ol>
<li>利用复合键值对等实现包含更多信息的倒排索引。</li>
</ol>
<p><strong><strong>附Java源码：</strong></strong></p>
<script src="https://gist.github.com/5443748.js?file=InvertedIndex.java"></script>

<p><strong>参考：</strong><br>[1]. 《实战Hadoop》</p>
]]></content>
    <category scheme="http://beforeload.github.io/tags/Java/" term="Java"/>
    <category scheme="http://beforeload.github.io/tags/Hadoop/" term="Hadoop"/>
    <category scheme="http://beforeload.github.io/tags/Algorithm/" term="Algorithm"/>
    <category scheme="http://beforeload.github.io/categories/Hadoop/" term="Hadoop"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[MapReduce]]></title>
    <link href="http://beforeload.github.io/2013/04/13/analyze-mapreduce/"/>
    <id>http://beforeload.github.io/2013/04/13/analyze-mapreduce/</id>
    <published>2013-04-12T18:56:30.000Z</published>
    <updated>2013-05-27T14:16:43.291Z</updated>
    <content type="html"><![CDATA[<p>写在前面的话：看了N多MapReduce方面的理论知识，一直想写写自己对MapReduce的理解。</p>
<h2>MapReduce 编程模型</h2>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre><span class="label">map:</span>(K1, V1) -&gt<span class="comment">; list(K2, V2)</span>
<span class="label">reduce:</span> (k2, list(V2)) -&gt<span class="comment">; list(K2, V2)</span>
</pre></td></tr></table></figure>

<p>简而言之就是 <strong><em> 输入-&gt; Mappers -&gt; 中间数据 -&gt; Reducer -&gt; 输出 </em></strong> 这样的一个过程，把输入<code>(key, value)</code>经过map和reduce函数转换成另一个或一批<code>(key, value)</code>对输出即可。</p>
<a name="more"></a>

<h3>Mapper</h3>
<p>Map阶段，MapReduce对任务输入数据分割，切割成固定大小的片段(splits)，对每个split进一步分解成一批键值对<code>(K1, V1)</code>。然后Hadoop为每个split创建Map任务(Mapper)，执行自定义的<code>map()</code>。</p>
<p>将split中的<code>(K1, V1)</code>键值对输入，得到结果为<code>(K2, V2)</code>的中间结果。<code>map()</code>的功能到这里并没有结束，因为我们在reduce阶段需要的输入格式是<code>(K2, list(V2))</code>，所以还需要对Mapper输出结果<code>(K2, V2)</code>进行合并(Combine过程)，即将中间结果中有相同key值(如：K2)的多组<code>(key, value)</code>对合并成一对(形成<code>(K2, list(V2))</code>)。key值范围决定了这些元组分组，对应不同的Reduce任务(Reducer)。</p>
<p><em>Tips:</em></p>
<ol>
<li>一个类作为mapper，要继承MapReduceBase基类并实现Mapper接口；</li>
<li>Mapper接口负责数据处理阶段。采用形式为<code>Mapper&lt;K1, V1, K2, V2&gt;</code> Java泛型；</li>
<li>Mapper只有一个方法——map，用于处理一个单独的键/值对。<figure class="highlight lang-Java"><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre><span class="keyword">void</span> map(K1 key, V1 value, OutputCollector&lt;K2, V2&gt; output, Reporter reporter)
    <span class="keyword">throws</span> IOException
</pre></td></tr></table></figure>

</li>
</ol>
<h3>Reducer</h3>
<p>Reduce阶段，数据整合，排序。然后调用自定义函数<code>reduce()</code>，输入<code>(K2, list(V2))</code>，得到键值对<code>&lt;K3, V3&gt;</code>输出到HDFS上。</p>
<p><em>Tips:</em></p>
<ol>
<li>Reducers数目在mapred-site.xml中决定，属性是<code>mapred.reduce.tasks</code>，默认值是 1，<code>job.setNumReduceTasks()</code>方法也可以用于设置，<strong>这是一个很重要的值</strong>；</li>
<li><p>reducer的实现首先必须在MapReduce基类上扩展，允许配置和清理。它必须实现Reducer接口实现<strong>reduce</strong>方法: </p>
<figure class="highlight lang-Java"><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre><span class="keyword">void</span> reduce(K2 key, Iterator&lt;V2&gt; values, OutputCollector&lt;K3, V3&gt; output, 
        Reporter reporter) <span class="keyword">throws</span> IOException
</pre></td></tr></table></figure>
</li>
<li><p><code>reduce()</code>函数最后生成的列表<code>(K3, V3)</code>可能为空；</p>
</li>
<li>map阶段和reduce阶段中间还有partitioner的工作：负责将mapper的结果输出给不同的reducer。</li>
</ol>
<h3>Hadoop的MapReduce</h3>
<p>Hadoop框架的核心是Map和Reduce操作，但不仅仅如此，还包括：</p>
<p><strong><em> data spliting(数据分割), shuffling(洗牌), Partitioning(分组), Combining(合并) </em></strong></p>
<p>以及各种格式的输入输出数据。</p>
<h3>Shuffler</h3>
<p>Mapper的按key值分为R份(R即为上面说到的Reducers的数目)，划分时通常采用hash函数，如<code>Hash(key) mod R</code>。目的是保证某一范围内的key一定由某个Reducer来处理。</p>
<p><em>Tips:</em></p>
<ol>
<li>洗牌之后相同的key对应的键值对放入相同的Reducer，不同的键也可以放入相同的Reducer。具体放入的位置由Partitioner决定。</li>
</ol>
<h3>Partitioner:重定向Mapper输出</h3>
<p>并不是数据排序好就是最好的。利用并行计算，不能仅仅靠一个reducer，那样就不是“云”而是“雨点”。当多个reducer一起使用时，默认的做法是对键值对进行hash来确定reducer。</p>
<p><em>Tips:</em></p>
<ol>
<li>Hadoop通过HashPartitioner类强制执行Partitioner策略。但HashPartitioner有时会出错；</li>
<li>量身定制partitioner，只需要实现<code>configure()</code>和<code>getPartition()</code>两个函数，前者将Hadoop对作业的配置应用在patitioner上，后者返回一个0到reduce任务数之间的整数，指向键/值对将要发送到的reducer。</li>
</ol>
<h3>Combiner: 本地reduce</h3>
<p>合并Mapper输出，即将多个key相同的<code>&lt;key, value&gt;</code>合并成一对。Combine过程和Reduce过程类似，很多情况下可以直接使用reduce函数，但Combiner过程是Mapper的一部分，在map函数后执行。</p>
<p><em>Tips：</em></p>
<ol>
<li>Hadoop并不保证对一个Mapper执行多少次Combine过程，所以我们应该做到无论Combine过程执行多少次，得到结果都一样；</li>
<li>中间结果的读取，JobTracker介入，负责通知中间文件的位置；</li>
<li>Mapper输出结果不在HDFS上而在本地磁盘上，出于时效性考虑，任务结束后删除，而HDFS的备份机制会造成性能损失，没有必要。</li>
</ol>
<h3>讨论：</h3>
<p>很多时候Rudecer产生的R个结果不是我们真正需要的最终结果，此时会把R个结果作为另一个计算的输入，开始另一个MapReduce任务，即任务管道。</p>
<h3>总结:</h3>
<p>MapReduce的集群行为(即MapReduce运行在大规模集群上的过程)，要完成一个并行计算，需要<em>_</em>任务调度与执行，本地计算，Shuffle，合并Mapper输出，读取中间结果，任务管道等一系列环节共同支撑计算的过程。</p>
]]></content>
    <category scheme="http://beforeload.github.io/tags/Hadoop/" term="Hadoop"/>
    <category scheme="http://beforeload.github.io/tags/MapReduce/" term="MapReduce"/>
    <category scheme="http://beforeload.github.io/categories/Hadoop/" term="Hadoop"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[From Jekyll to Hexo]]></title>
    <link href="http://beforeload.github.io/2013/04/12/migrate_jekyll_to_hexo/"/>
    <id>http://beforeload.github.io/2013/04/12/migrate_jekyll_to_hexo/</id>
    <published>2013-04-12T05:11:40.000Z</published>
    <updated>2013-05-25T15:21:51.663Z</updated>
    <content type="html"><![CDATA[<h3>从Jekyll迁移到Hexo</h3>
<ol>
<li><a href="http://zespia.tw/hexo">Hexo</a>! </li>
<li><a href="http://zespia.tw/hexo/docs">documentation</a> 文档</li>
</ol>
<a name="more"></a>

<p><strong>优点：</strong></p>
<ul>
<li>真的很快，上手很easy</li>
</ul>
<p><strong>优待改进的地方：</strong></p>
<ul>
<li>主题欠缺，有时间改改主题</li>
</ul>
<h3>记录：</h3>
<ol>
<li>用jiathis代替addthis；</li>
<li>找了源码加文档，终于还是在文档上找到了excerpt的用法，原来只需要在md里面加<code>&lt;!-- more --&gt;</code>即可。</li>
</ol>
]]></content>
    <category scheme="http://beforeload.github.io/tags/Memory/" term="Memory"/>
    <category scheme="http://beforeload.github.io/categories/Memory/" term="Memory"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[理解深度优先和广度优先]]></title>
    <link href="http://beforeload.github.io/2013/04/09/DFS-and-BFS/"/>
    <id>http://beforeload.github.io/2013/04/09/DFS-and-BFS/</id>
    <published>2013-04-09T05:14:20.000Z</published>
    <updated>2013-04-12T18:49:30.000Z</updated>
    <content type="html"><![CDATA[<h4>问题：</h4>
<p>迷宫, 1为墙壁， 0为可以走的路， 只能横着走和竖着走，求解左上角到右下角的路线。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
</pre></td><td class="code"><pre>int maze<span class="matrix">[<span class="number">5</span>]</span><span class="matrix">[<span class="number">5</span>]</span> = <span class="cell">{
    <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,
    <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>,
    <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,
    <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>,
}</span>;
</pre></td></tr></table></figure>

<a name="more"></a>

<h3>思路：</h3>
<p><strong>解法一：</strong></p>
<p>深度优先搜索(DFS, Depth First Search):每次搜索完各个方向相邻的点之后，取其中一个相邻的点走下去，一直走到无路可走了再退回来(回溯)，取另一个相邻的点再走下去。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td class="code"><pre>将起点标记为已走过并压栈；
<span class="function"><span class="title">while</span> <span class="params">(栈非空)</span> {
    从栈顶弹出一个点P；
    <span class="title">if</span> <span class="params">(p这个点是终点)</span> {
        <span class="title">break</span>;
    }
    沿右、下、左、上四个方向探索相邻的点;
    <span class="title">if</span> <span class="params">(和p相邻的点有路可走，并且还没走过)</span> {
        将相邻的点标记为已走过并压栈，它的前趋就是<span class="title">p</span>点;
    }
}
<span class="title">if</span> <span class="params">(p点是终点)</span> {
    打印<span class="title">p</span>点的坐标；
    <span class="title">while</span> <span class="params">(p点有前趋)</span> {
        <span class="title">p</span>点 = <span class="title">p</span>点的前趋;
        打印<span class="title">p</span>点的坐标;
    }
} <span class="title">else</span> {
    没有路线可以到达终点;
}
</pre></td></tr></table></figure>

<p><strong><em>附源码如下：</em></strong></p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
</pre></td><td class="code"><pre><span class="preprocessor">#include &lt;stdio.h&gt;</span>
<span class="preprocessor">#define MAX_ROW 5</span>
<span class="preprocessor">#define MAX_COL 5</span>

<span class="keyword">struct</span> point {
    <span class="keyword">int</span> row, col;
} stack[<span class="number">512</span>];

<span class="keyword">int</span> top = <span class="number">0</span>;

<span class="keyword">void</span> push(<span class="keyword">struct</span> point p)
{
	stack[top++] = p;
}

<span class="keyword">struct</span> point pop(<span class="keyword">void</span>)
{
	<span class="keyword">return</span> stack[--top];
}

<span class="keyword">int</span> is_empty(<span class="keyword">void</span>)
{
	<span class="keyword">return</span> top == <span class="number">0</span>;
}

<span class="keyword">int</span> maze[MAX_ROW][MAX_COL] = {
	<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,
	<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>,
	<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,
	<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>,
	<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>,
};

<span class="keyword">void</span> print_maze(<span class="keyword">void</span>)
{
	<span class="keyword">int</span> i, j;
	<span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; MAX_ROW; i++) {
		<span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; MAX_COL; j++) {
			printf(<span class="string">"%d "</span>, maze[i][j]);
		}
		putchar(<span class="string">'\n'</span>);
	}
	printf(<span class="string">"************\n"</span>);
}

<span class="keyword">struct</span> point predecessor[MAX_ROW][MAX_COL] = {
	{ {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}},
	{ {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}},
	{ {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}},
	{ {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}},
	{ {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}, {-<span class="number">1</span>, -<span class="number">1</span>}},
};

<span class="keyword">void</span> visit(<span class="keyword">int</span> row, <span class="keyword">int</span> col, <span class="keyword">struct</span> point pre)
{
	<span class="keyword">struct</span> point visit_point = {
		row, col
	};
	maze[row][col] = <span class="number">2</span>;
	predecessor[row][col] = pre;
	push(visit_point);
}

<span class="keyword">int</span> main(<span class="keyword">void</span>)
{
	<span class="keyword">struct</span> point p = {
		<span class="number">0</span>, <span class="number">0</span>
	};
	maze[p<span class="variable">.row</span>][p<span class="variable">.col</span>] = <span class="number">2</span>;
	push(p);

	<span class="keyword">while</span> (!is_empty()) {
		p = pop();
		<span class="keyword">if</span> (p<span class="variable">.row</span> == MAX_ROW - <span class="number">1</span> && p<span class="variable">.col</span> == MAX_COL - <span class="number">1</span>) {
			<span class="keyword">break</span>;
		}
		<span class="keyword">if</span> (p<span class="variable">.col</span> + <span class="number">1</span> &lt; MAX_COL && maze[p<span class="variable">.row</span>][p<span class="variable">.col</span> + <span class="number">1</span>] == <span class="number">0</span>) {
			visit(p<span class="variable">.row</span>, p<span class="variable">.col</span> + <span class="number">1</span>, p);
		}
		<span class="keyword">if</span> (p<span class="variable">.row</span> + <span class="number">1</span> &lt; MAX_ROW && maze[p<span class="variable">.row</span> + <span class="number">1</span>][p<span class="variable">.col</span>] == <span class="number">0</span>) {
			visit(p<span class="variable">.row</span> + <span class="number">1</span>, p<span class="variable">.col</span>, p);
		}
		<span class="keyword">if</span> (p<span class="variable">.col</span> - <span class="number">1</span> &gt;= <span class="number">0</span> && maze[p<span class="variable">.row</span>][p<span class="variable">.col</span> - <span class="number">1</span>] == <span class="number">0</span>) {
			visit(p<span class="variable">.row</span>, p<span class="variable">.col</span> - <span class="number">1</span>, p);
		}
		<span class="keyword">if</span> (p<span class="variable">.row</span> - <span class="number">1</span> &gt;= <span class="number">0</span> && maze[p<span class="variable">.row</span> - <span class="number">1</span>][p<span class="variable">.col</span>] == <span class="number">0</span>) {
			visit(p<span class="variable">.row</span> - <span class="number">1</span>, p<span class="variable">.col</span>, p);
		}
		print_maze();
	}
	<span class="keyword">if</span> (p<span class="variable">.col</span> == MAX_COL - <span class="number">1</span> && p<span class="variable">.row</span> == MAX_ROW - <span class="number">1</span>) {
		printf(<span class="string">"(%d, %d)\n"</span>, p<span class="variable">.row</span>, p<span class="variable">.col</span>);
		<span class="keyword">while</span> (predecessor[p<span class="variable">.row</span>][p<span class="variable">.col</span>]<span class="variable">.row</span> != -<span class="number">1</span>) {
			p = predecessor[p<span class="variable">.row</span>][p<span class="variable">.col</span>];
			printf(<span class="string">"(%d, %d)\n"</span>, p<span class="variable">.row</span>, p<span class="variable">.col</span>);
		}
	} <span class="keyword">else</span> {
		printf(<span class="string">"No path!\n"</span>);
	}
	<span class="keyword">return</span> <span class="number">0</span>;
}
</pre></td></tr></table></figure>

<p><strong>DFS 优化：</strong></p>
<p>代码没有什么难懂的地方，不过有很多可以优化的地方，例如在predecessor这个数据结构上，浪费了太多的存储空间，可以做以下优化：</p>
<ol>
<li><p>重新定义predecessor存储方式
<figure class="highlight"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre>struct point predecessor<span class="matrix">[MAX_ROW]</span><span class="matrix">[MAX_COL]</span> = <span class="cell">{ <span class="number">0</span> }</span>;
</pre></td></tr></table></figure>
所有的值定义为0,前趋点为上点，则将他赋值为1，前趋点为下点，则赋值为-1，前趋点为左点，则赋值为2,前趋点为右点，则赋值为-2；通过定义四个不同的值区分前趋点，减少了存储空间，相应的函数也要对应修改即可。</p>
</li>
<li><p>用递归取代predecessor数据结构</p>
</li>
</ol>
<p><strong>解法二：</strong>
广度优先搜索(BFS, Breadth First Search):
BFS沿各个方向上同时展开搜索，每个可以走通的方向轮流往前走一步。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td class="code"><pre>将起点标记为已经走过的队列
<span class="function"><span class="title">while</span> <span class="params">(队列非空)</span> {
    出队一个点<span class="title">p</span>;
    <span class="title">if</span> <span class="params">(p为终点)</span> {
        <span class="title">break</span>;
    }
    否则沿右下左上四个方向探索相邻的点
    <span class="title">if</span> <span class="params">(和p相邻的点有路走，且没有走过)</span> {
        将相邻的点标记为已经走过并入队列，他的前趋就是刚出队的<span class="title">p</span>点;
    }
    <span class="title">if</span> <span class="params">(p点是终点)</span> {
        打印<span class="title">p</span>点的坐标;
        <span class="title">while</span> <span class="params">(p点有前趋)</span> {
            <span class="title">p</span>点 = <span class="title">p</span> 点的前趋;
            打印 <span class="title">p</span> 点的坐标;
        }
    } <span class="title">else</span> {
        没有到达终点的路线;
    }
}
</pre></td></tr></table></figure>

<p>BFS相比较于DFS，BFS可以找到从起点到终点的最短路径。</p>
<p><strong><em>附源码如下:</em></strong></p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
</pre></td><td class="code"><pre><span class="preprocessor">#include &lt;stdio.h&gt;</span>
<span class="preprocessor">#define MAX_ROW 5</span>
<span class="preprocessor">#define MAX_COL 5</span>

<span class="keyword">struct</span> point {
	<span class="keyword">int</span> row, col, predecessor;
} queue[<span class="number">512</span>];

<span class="keyword">int</span> head = <span class="number">0</span>, tail = <span class="number">0</span>;

<span class="keyword">void</span> enqueue(<span class="keyword">struct</span> point p)
{
	queue[tail++] = p;
}

<span class="keyword">struct</span> point dequeue(<span class="keyword">void</span>)
{
	<span class="keyword">return</span> queue[head++];
}

<span class="keyword">int</span> is_empty(<span class="keyword">void</span>)
{
	<span class="keyword">return</span> head == tail;
}

<span class="keyword">int</span> maze[MAX_ROW][MAX_COL] = {
	<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,
	<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>,
	<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,
	<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>,
	<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>,
};

<span class="keyword">void</span> print_maze(<span class="keyword">void</span>)
{
	<span class="keyword">int</span> i, j;
	<span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; MAX_ROW; i++) {
		<span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; MAX_COL; j++) {
			printf(<span class="string">"%d "</span>, maze[i][j]);
		}
		putchar(<span class="string">'\n'</span>);
	}
	printf(<span class="string">"************\n"</span>);
}

<span class="keyword">void</span> visit(<span class="keyword">int</span> row, <span class="keyword">int</span> col)
{
	<span class="keyword">struct</span> point visit_point = {
		row, col, head - <span class="number">1</span>
	};
	maze[row][col] = <span class="number">2</span>;
	enqueue(visit_point);
}

<span class="keyword">int</span> main(<span class="keyword">void</span>)
{
	<span class="keyword">struct</span> point p = {
		<span class="number">0</span>, <span class="number">0</span>, -<span class="number">1</span>
	};
	maze[p<span class="variable">.row</span>][p<span class="variable">.col</span>] = <span class="number">2</span>;
	enqueue(p);

	<span class="keyword">while</span> (!is_empty()) {
		p = dequeue();
		<span class="keyword">if</span> (p<span class="variable">.row</span> == MAX_ROW - <span class="number">1</span> && p<span class="variable">.col</span> == MAX_COL - <span class="number">1</span>) {
			<span class="keyword">break</span>;
		}
		<span class="keyword">if</span> (p<span class="variable">.row</span> + <span class="number">1</span> &lt; MAX_ROW && maze[p<span class="variable">.row</span> + <span class="number">1</span>][p<span class="variable">.col</span>] == <span class="number">0</span>) {
			visit(p<span class="variable">.row</span> + <span class="number">1</span>, p<span class="variable">.col</span>);
		}
		<span class="keyword">if</span> (p<span class="variable">.col</span> + <span class="number">1</span> &lt; MAX_COL && maze[p<span class="variable">.row</span>][p<span class="variable">.col</span> + <span class="number">1</span>] == <span class="number">0</span>) {
			visit(p<span class="variable">.row</span>, p<span class="variable">.col</span> + <span class="number">1</span>);
		}
		<span class="keyword">if</span> (p<span class="variable">.col</span> - <span class="number">1</span> &gt;= <span class="number">0</span> && maze[p<span class="variable">.row</span>][p<span class="variable">.col</span> - <span class="number">1</span>] == <span class="number">0</span>) {
			visit(p<span class="variable">.row</span>, p<span class="variable">.col</span> - <span class="number">1</span>);
		}
		<span class="keyword">if</span> (p<span class="variable">.row</span> - <span class="number">1</span> &gt;= <span class="number">0</span> && maze[p<span class="variable">.row</span> - <span class="number">1</span>][p<span class="variable">.col</span>] == <span class="number">0</span>) {
			visit(p<span class="variable">.row</span> - <span class="number">1</span>, p<span class="variable">.col</span>);
		}
		print_maze();
	}
	<span class="keyword">if</span> (p<span class="variable">.row</span> == MAX_ROW - <span class="number">1</span> && p<span class="variable">.col</span> == MAX_COL - <span class="number">1</span>) {
		printf(<span class="string">"(%d, %d)\n"</span>, p<span class="variable">.row</span>, p<span class="variable">.col</span>);
		<span class="keyword">while</span> (p<span class="variable">.predecessor</span> != -<span class="number">1</span>) {
			p = queue[p<span class="variable">.predecessor</span>];
			printf(<span class="string">"(%d, %d)\n"</span>, p<span class="variable">.row</span>, p<span class="variable">.col</span>);
		}
	} <span class="keyword">else</span> {
		printf(<span class="string">"No path!\n"</span>);
	}
}
</pre></td></tr></table></figure>

<h4>参考：</h4>
<ol>
<li>《Linux C编程一站式学习》<a href="http://learn.akae.cn/media/ch12.html">栈与队列</a></li>
</ol>
]]></content>
    <category scheme="http://beforeload.github.io/tags/C/" term="C"/>
    <category scheme="http://beforeload.github.io/tags/Data-Structure/" term="Data Structure"/>
    <category scheme="http://beforeload.github.io/tags/Algorithm/" term="Algorithm"/>
    <category scheme="http://beforeload.github.io/categories/Algorithm/" term="Algorithm"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[理解 Hadoop 的 Java API]]></title>
    <link href="http://beforeload.github.io/2013/04/06/hdfs-java-api/"/>
    <id>http://beforeload.github.io/2013/04/06/hdfs-java-api/</id>
    <published>2013-04-06T07:14:42.000Z</published>
    <updated>2013-05-21T15:16:36.603Z</updated>
    <content type="html"><![CDATA[<h3>案例</h3>
<h4>上传本地文件到 HDFS</h4>
<figure class="highlight lang-Java"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="code"><pre><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> copyFile(String src, String dst, String config) <span class="keyword">throws</span> IOException{
    Configuration conf = <span class="keyword">new</span> Configuration();
    conf.addResource(<span class="keyword">new</span> Path(config));
    FileSystem hdfs = FileSystem.get(conf);
    Path srcPath = <span class="keyword">new</span> Path(src);
    Path dstPath = <span class="keyword">new</span> Path(dst);
    hdfs.copyFromLocalFile(srcPath, dstPath);
    System.out.println(<span class="string">"Upload to "</span> + conf.get(<span class="string">"fs.default.name"</span>));
    
    FileStatus files[] = hdfs.listStatus(dstPath);
    <span class="keyword">for</span> (FileStatus file : files) {
        System.out.println(file.getPath());
    }
    hdfs.close();
}
</pre></td></tr></table></figure>

<a name="more"></a>

<h4>创建 HDFS 文件</h4>
<figure class="highlight lang-Java"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="code"><pre><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> createFile(String dst, String config) <span class="keyword">throws</span> IOException{
    Configuration conf = <span class="keyword">new</span> Configuration();
    conf.addResource(<span class="keyword">new</span> Path(config));
    String content = <span class="string">"Hello World,beforeload"</span>;
    <span class="keyword">byte</span>[] buff = content.getBytes();
    FileSystem hdfs = FileSystem.get(conf);
    Path dfsPath = <span class="keyword">new</span> Path(dst);
    FSDataOutputStream os = hdfs.create(dfsPath);
    os.write(buff,<span class="number">0</span>,buff.length);
    os.write(content.getBytes(<span class="string">"UTF-8"</span>));
    os.close();
    hdfs.close();
}
</pre></td></tr></table></figure>

<h4>重命名 HDFS 文件</h4>
<figure class="highlight lang-Java"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
</pre></td><td class="code"><pre><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> rename(String oldName, String newName, String config)
        <span class="keyword">throws</span> IOException {
    Configuration conf = <span class="keyword">new</span> Configuration();
    conf.addResource(<span class="keyword">new</span> Path(config));
    FileSystem hdfs = FileSystem.get(conf);
    Path oldPath = <span class="keyword">new</span> Path(oldName);
    Path newPath = <span class="keyword">new</span> Path(newName);
    <span class="keyword">boolean</span> isRename = hdfs.rename(oldPath, newPath);
}
</pre></td></tr></table></figure>

<h4>删除 HDFS 上的文件</h4>
<figure class="highlight lang-Java"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td class="code"><pre><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> deleteFile(String path, String config) <span class="keyword">throws</span> IOException {
    Configuration conf = <span class="keyword">new</span> Configuration();
    conf.addResource(<span class="keyword">new</span> Path(config));
    FileSystem hdfs = FileSystem.get(conf);
    Path deletePath = <span class="keyword">new</span> Path(path);
    <span class="keyword">boolean</span> isDeleted = hdfs.delete(deletePath, <span class="keyword">false</span>);
    <span class="comment">// 递归删除</span>
    <span class="comment">// boolean isDelete = hdfs.delete(deletePath, true);</span>
    System.out.println(<span class="string">"delete? "</span>+ isDeleted);
}
</pre></td></tr></table></figure>

<h4>查看 HDFS 文件的最后修改时间</h4>
<figure class="highlight lang-Java"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
</pre></td><td class="code"><pre><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> getTime(String path, String config) <span class="keyword">throws</span> IOException{
    Configuration conf = <span class="keyword">new</span> Configuration();
    conf.addResource(<span class="keyword">new</span> Path(config));
    FileSystem hdfs = FileSystem.get(conf);
    Path filePath = <span class="keyword">new</span> Path(path);
    FileStatus fileStatus = hdfs.getFileStatus(filePath);
    <span class="keyword">long</span> modifyTime = fileStatus.getModificationTime();
    System.out.println(<span class="string">"Modification time is:"</span> + modifyTime);
}
</pre></td></tr></table></figure>

<h4>查看某个 HDFS 文件是否存在</h4>
<figure class="highlight lang-Java"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
</pre></td><td class="code"><pre><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> isExist(String path, String config) <span class="keyword">throws</span> IOException {
    Configuration conf = <span class="keyword">new</span> Configuration();
    conf.addResource(<span class="keyword">new</span> Path(config));
    FileSystem hdfs = FileSystem.get(conf);
    <span class="keyword">boolean</span> isExist = hdfs.exists(<span class="keyword">new</span> Path(path));
    System.out.println(<span class="string">"Exist?"</span>+ isExist);
}
</pre></td></tr></table></figure>

<h4>查找某个文件在 HDFS 集群的位置</h4>
<figure class="highlight lang-Java"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="code"><pre><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> getFileBlockLocation(String path, String config)
        <span class="keyword">throws</span> IOException {
    Configuration conf = <span class="keyword">new</span> Configuration();
    conf.addResource(<span class="keyword">new</span> Path(config));
    FileSystem hdfs = FileSystem.get(conf);
    Path filePath = <span class="keyword">new</span> Path(path);
    FileStatus fileStatus = hdfs.getFileStatus(filePath);
    BlockLocation[] blockLocations = hdfs.getFileBlockLocations(fileStatus,
            <span class="number">0</span>, fileStatus.getLen());

    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; blockLocations.length; i++) {
        String[] hosts = blockLocations[i].getHosts();
        System.out.println(<span class="string">"block"</span> + i + <span class="string">"location:"</span> + hosts[i]);
    }
}
</pre></td></tr></table></figure>

<h4>获取 HDFS 集群上所有节点的名称</h4>
<figure class="highlight lang-Java"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="code"><pre><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> getHostName(String config) <span class="keyword">throws</span> IOException {
    Configuration conf = <span class="keyword">new</span> Configuration();
    conf.addResource(<span class="keyword">new</span> Path(config));
    FileSystem fs = FileSystem.get(conf);
    DistributedFileSystem hdfs = (DistributedFileSystem) fs;
    DatanodeInfo[] dataNodeStats = hdfs.getDataNodeStats();
    String[] names = <span class="keyword">new</span> String[dataNodeStats.length];
    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; dataNodeStats.length; i++) {
        names[i] = dataNodeStats[i].getHostName();
        System.out.println(<span class="string">"node "</span> + i + <span class="string">" name "</span> + names[i]);
    }
}
</pre></td></tr></table></figure>

<h3>问题</h3>
<ol>
<li>&quot;Wrong FS expected: file:///&quot;</li>
</ol>
<p>这个问题其实严格意义上并不属于API调用方面的问题，具体问题出现的原因不得而知，不过在查阅资料一番后还是得出了问题的解决方法。</p>
<ul>
<li>stackoverflow上给出<a href="http://stackoverflow.com/questions/7969519/what-is-the-loading-order-of-the-configuration-files-in-hadoop/7995180#7995180">问题</a>的解决方法，不过经过尝试后，也只能发出感叹：”It doesn&#39;t work!&quot; </li>
<li>幸好在<a href="http://www.opensourceconnections.com/2013/03/24/hdfs-debugging-wrong-fs-expected-file-exception">Doug的博客</a>上给出了解答，通过添加一行代码即可<figure class="highlight lang-Java"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre>conf.addResource(<span class="keyword">new</span> Path(<span class="string">"/root/hadoop-0.20.2/conf/core-site.xml"</span>));
</pre></td></tr></table></figure>

</li>
</ul>
<h3>讨论</h3>
<p><strong><em>附源码如下：</em></strong></p>
<figure class="highlight lang-Java"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
</pre></td><td class="code"><pre><span class="keyword">import</span> java.io.IOException;

<span class="keyword">import</span> org.apache.hadoop.conf.Configuration;
<span class="keyword">import</span> org.apache.hadoop.fs.BlockLocation;
<span class="keyword">import</span> org.apache.hadoop.fs.FSDataOutputStream;
<span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;
<span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;
<span class="keyword">import</span> org.apache.hadoop.fs.Path;
<span class="keyword">import</span> org.apache.hadoop.hdfs.DistributedFileSystem;
<span class="keyword">import</span> org.apache.hadoop.hdfs.protocol.DatanodeInfo;

<span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Utils</span> {</span>
	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> main(String[] args) <span class="keyword">throws</span> IOException {
		String src, dst1, config, dst2, oldName, newName;
		src = <span class="string">"/root/word.txt"</span>;
		dst1 = <span class="string">"/"</span>;
		config = <span class="string">"/root/hadoop-0.20.2/conf/core-site.xml"</span>;
		<span class="comment">// copyFile(src, dst1, config);</span>

		dst2 = <span class="string">"/test.txt"</span>;
		<span class="comment">// createFile(dst2, config);</span>

		oldName = dst2;
		newName = <span class="string">"/test1.txt"</span>;
		<span class="comment">// rename(oldName, newName, config);</span>

		<span class="comment">// deleteFile(dst2, config);</span>
		<span class="comment">// getTime(dst1, config);</span>

		<span class="comment">// isExist(dst2, config);</span>
		<span class="comment">// isExist(dst1, config);</span>

		<span class="comment">// getFileBlockLocation(dst2, config);</span>

		getHostName(config);
	}

	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> copyFile(String src, String dst, String config)
			<span class="keyword">throws</span> IOException {
		Configuration conf = <span class="keyword">new</span> Configuration();
		conf.addResource(<span class="keyword">new</span> Path(config));
		FileSystem hdfs = FileSystem.get(conf);
		Path srcPath = <span class="keyword">new</span> Path(src);
		Path dstPath = <span class="keyword">new</span> Path(dst);
		hdfs.copyFromLocalFile(srcPath, dstPath);
		System.out.println(<span class="string">"Upload to "</span> + conf.get(<span class="string">"fs.default.name"</span>));

		FileStatus files[] = hdfs.listStatus(dstPath);
		<span class="keyword">for</span> (FileStatus file : files) {
			System.out.println(file.getPath());
		}
		hdfs.close();
	}

	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> createFile(String dst, String config) <span class="keyword">throws</span> IOException {
		Configuration conf = <span class="keyword">new</span> Configuration();
		conf.addResource(<span class="keyword">new</span> Path(config));
		String content = <span class="string">"Hello World,beforeload"</span>;
		<span class="keyword">byte</span>[] buff = content.getBytes();
		FileSystem hdfs = FileSystem.get(conf);
		Path dfsPath = <span class="keyword">new</span> Path(dst);
		FSDataOutputStream os = hdfs.create(dfsPath);
		os.write(buff, <span class="number">0</span>, buff.length);
		os.write(content.getBytes(<span class="string">"UTF-8"</span>));
		os.close();
		hdfs.close();
	}

	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> rename(String oldName, String newName, String config)
			<span class="keyword">throws</span> IOException {
		Configuration conf = <span class="keyword">new</span> Configuration();
		conf.addResource(<span class="keyword">new</span> Path(config));
		FileSystem hdfs = FileSystem.get(conf);
		Path oldPath = <span class="keyword">new</span> Path(oldName);
		Path newPath = <span class="keyword">new</span> Path(newName);
		<span class="keyword">boolean</span> isRename = hdfs.rename(oldPath, newPath);
	}

	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> deleteFile(String path, String config)
			<span class="keyword">throws</span> IOException {
		Configuration conf = <span class="keyword">new</span> Configuration();
		conf.addResource(<span class="keyword">new</span> Path(config));
		FileSystem hdfs = FileSystem.get(conf);
		Path deletePath = <span class="keyword">new</span> Path(path);
		<span class="keyword">boolean</span> isDeleted = hdfs.delete(deletePath, <span class="keyword">false</span>);
		<span class="comment">// 递归删除</span>
		<span class="comment">// boolean isDelete = hdfs.delete(deletePath, true);</span>
		System.out.println(<span class="string">"delete? "</span> + isDeleted);
	}

	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> getTime(String path, String config) <span class="keyword">throws</span> IOException {
		Configuration conf = <span class="keyword">new</span> Configuration();
		conf.addResource(<span class="keyword">new</span> Path(config));
		FileSystem hdfs = FileSystem.get(conf);
		Path filePath = <span class="keyword">new</span> Path(path);
		FileStatus fileStatus = hdfs.getFileStatus(filePath);
		<span class="keyword">long</span> modifyTime = fileStatus.getModificationTime();
		System.out.println(<span class="string">"Modification time is:"</span> + modifyTime);
	}

	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> isExist(String path, String config) <span class="keyword">throws</span> IOException {
		Configuration conf = <span class="keyword">new</span> Configuration();
		conf.addResource(<span class="keyword">new</span> Path(config));
		FileSystem hdfs = FileSystem.get(conf);
		<span class="keyword">boolean</span> isExist = hdfs.exists(<span class="keyword">new</span> Path(path));
		System.out.println(<span class="string">"Exist?"</span> + isExist);
	}

	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> getFileBlockLocation(String path, String config)
			<span class="keyword">throws</span> IOException {
		Configuration conf = <span class="keyword">new</span> Configuration();
		conf.addResource(<span class="keyword">new</span> Path(config));
		FileSystem hdfs = FileSystem.get(conf);
		Path filePath = <span class="keyword">new</span> Path(path);
		FileStatus fileStatus = hdfs.getFileStatus(filePath);
		BlockLocation[] blockLocations = hdfs.getFileBlockLocations(fileStatus,
				<span class="number">0</span>, fileStatus.getLen());

		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; blockLocations.length; i++) {
			String[] hosts = blockLocations[i].getHosts();
			System.out.println(<span class="string">"block"</span> + i + <span class="string">"location:"</span> + hosts[i]);
		}
	}

	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> getHostName(String config) <span class="keyword">throws</span> IOException {
		Configuration conf = <span class="keyword">new</span> Configuration();
		conf.addResource(<span class="keyword">new</span> Path(config));
		FileSystem fs = FileSystem.get(conf);
		DistributedFileSystem hdfs = (DistributedFileSystem) fs;
		DatanodeInfo[] dataNodeStats = hdfs.getDataNodeStats();
		String[] names = <span class="keyword">new</span> String[dataNodeStats.length];
		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; dataNodeStats.length; i++) {
			names[i] = dataNodeStats[i].getHostName();
			System.out.println(<span class="string">"node "</span> + i + <span class="string">" name "</span> + names[i]);
		}
	}
}
</pre></td></tr></table></figure>

<h4>参考书籍：</h4>
<ol>
<li>《Hadoop实战》—— &quot;Hadoop in Action&quot;</li>
<li>《实战Hadoop》—— &quot;开启通向云计算的捷径&quot;</li>
<li><a href="http://hadoop.apache.org/core/docs/current/api/org/apache/hadoop/fs/package-summary.html">Hadoop Java API 官方文档</a></li>
</ol>
]]></content>
    <category scheme="http://beforeload.github.io/tags/Java/" term="Java"/>
    <category scheme="http://beforeload.github.io/tags/Hadoop/" term="Hadoop"/>
    <category scheme="http://beforeload.github.io/tags/API/" term="API"/>
    <category scheme="http://beforeload.github.io/tags/HDFS/" term="HDFS"/>
    <category scheme="http://beforeload.github.io/categories/Hadoop/" term="Hadoop"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[k-th Order Statistic]]></title>
    <link href="http://beforeload.github.io/2013/04/05/k-th-order-statistic/"/>
    <id>http://beforeload.github.io/2013/04/05/k-th-order-statistic/</id>
    <published>2013-04-05T12:12:32.000Z</published>
    <updated>2013-05-25T15:20:51.707Z</updated>
    <content type="html"><![CDATA[<h3>问题描述:</h3>
<h6>问题来源: <a href="http://learn.akae.cn/media/ch11s05.html">线性查找</a></h6>
<ol>
<li>实现一个算法，在一组随机排列的数中找出最小的一个。你能想到的最直观的算法一定是Θ(n)的，想想有没有比Θ(n)更快的算法？</li>
<li>在一组随机排列的数中找出第二小的，这个问题比上一个稍复杂，你能不能想出Θ(n)的算法？</li>
<li>进一步泛化，在一组随机排列的数中找出第k小的，这个元素称为<code>k-th Order Statistic</code>。能想到的最直观的算法肯定是先把这些数排序然后取第k个，时间复杂度和排序算法相同，可以是Θ(nlgn)。这个问题虽然比前两个问题复杂，但它也有平均情况下时间复杂度是Θ(n)的算法</li>
</ol>
<a name="more"></a>

<h3>求解及算法：</h3>
<p>求一组数中最小值，对于数组而言是一个很easy且常见的问题。
解决算法也很容易:</p>
<pre><code><span class="keyword">int</span> minimum(<span class="keyword">int</span> arr[])
{
    <span class="keyword">int</span> j,temp;
    temp = arr[<span class="number">0</span>];

    <span class="keyword">for</span> (j = <span class="number">1</span>; j &lt; N; j++) {
        <span class="keyword">if</span>(temp &gt; arr[j]){
            swap(&amp;temp,&amp;arr[j]);
        }
    }
    <span class="keyword">return</span> temp;
}
</code></pre>
<p>算法复杂度为Θ(n),且只需要遍历一次即可得出结果；</p>
<ol>
<li>在数组中求解第二小值也不是一件难事，只要想清楚求解的思路和步骤，问题便可迎刃而解。
当然算法可能性多种多样，我所采用的方法简单粗暴：</li>
</ol>
<p><figure class="highlight lang-C"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="code"><pre><span class="javadoc">/** 第二小的数 */</span>
<span class="keyword">int</span> second_min(<span class="keyword">int</span> arr[])
{
    <span class="keyword">int</span> min, smin, i;
        min = smin = arr[<span class="number">0</span>];
    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; N; i++) {
        <span class="keyword">if</span> (arr[i] &lt;= min) {
            smin = min;
            min = arr[i];
        }
    }
    <span class="keyword">return</span> smin;
}
</pre></td></tr></table></figure>
在每次找到更小的数字时，把当前的数字赋值给第二小的数字，算法复杂度同样是Θ(n),且只需遍历一次即可得出结果。</p>
<ol>
<li>对于求<code>k-th Order Statistic</code>元素，常规的解法是先排序，后根据排出的顺序，得到第k小的值。时间复杂度等同与排序的时间复杂度。当然，我们不需要完全排出顺序也能得到结果，学过<code>quick sort</code>之后，根据<code>pivot</code>元素的位置与k值比较，稍作修改快排算法即可得出解法。
求解算法如下：</li>
</ol>
<pre><code>
int partition(int start, int end)
{
    int pivot, mid, i;
    pivot = arr[start];
    mid = start;
    for (i = start + 1; i &lt;= end; i++) {
        if (arr[i] &lt; pivot) {
            mid++;
            swap(&amp;arr[i], &amp;arr[mid]);
        }
    }
    swap(&amp;arr[mid], &amp;arr[start]);
    return mid;
}

int order_statistic(int start, int end, int k)
{
    int i;
    if (start &lt; end) {
        i = partition(start, end);
        if (k == i) {
            return i;
        } else if (k &gt; i) {
            order_statistic(i + 1, end, k);
        } else {
            order_statistic(start, i - 1, k);
        }
    }
}
</code></pre>

<p>算法复杂度等同与快排是Θ(nlgn)，平均复杂度为Θ(n)。</p>
<p>附上完整C语言代码：</p>
<pre><code>#include &lt;stdio.h&gt;
#define N 10
int arr[N] = { 3, 4, 1, 3, 5, 6, 7, 9, 1, 2 };

int partition(int start, int end)
{
    int pivot, mid, i;
    pivot = arr[start];
    mid = start;
    for (i = start + 1; i &lt;= end; i++) {
        if (arr[i] &lt; pivot) {
            mid++;
            swap(&amp;arr[i], &amp;arr[mid]);
        }
    }
    swap(&amp;arr[mid], &amp;arr[start]);
    return mid;
}

int order_statistic(int start, int end, int k)
{
    int i;
    if (start &lt; end) {
        i = partition(start, end);
        if (k == i) {
            return i;
        } else if (k &gt; i) {
            order_statistic(i + 1, end, k);
        } else {
            order_statistic(start, i - 1, k);
        }
    }
}

int swap(int *a, int *b)
{
    int temp;
    temp = *b;
    *b = *a;
    *a = temp;
}

int main(int argc, const char *argv[])
{
    int i, k = 3, result;
    result = order_statistic(0, N - 1, k);
    for (i = 0; i &lt; N; i++) {
        printf("%d ", arr[i]);
    }
    printf("\n");
    printf("The %d-th Order Statistic is %d.\n", k + 1, arr[result]);
    return 0;
}
</code></pre>

<h3>讨论</h3>
<hr>
]]></content>
    <category scheme="http://beforeload.github.io/tags/C/" term="C"/>
    <category scheme="http://beforeload.github.io/tags/Algorithm/" term="Algorithm"/>
    <category scheme="http://beforeload.github.io/categories/Algorithm/" term="Algorithm"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[blog establish]]></title>
    <link href="http://beforeload.github.io/2013/04/03/blog-establish/"/>
    <id>http://beforeload.github.io/2013/04/03/blog-establish/</id>
    <published>2013-04-03T15:11:12.000Z</published>
    <updated>2013-05-21T15:16:36.603Z</updated>
    <content type="html"><![CDATA[<p>新建第一篇博文，以纪念今天博客建立</p>
<p>一直在犹豫使用Jekyll还是Octopress搭建自己的博客,虽然后者基于前者做了一些优化之类的东西,但最终犹豫再三还是使用了Jekyll。没有使用过Octopress，不知道两者之间的区别在什么地方，不过相对于初学者，使用Jekyll还是非常容易上手的，具体的步骤参看<a href="http://jekyllbootstrap.com">Jekyll Bootstrap</a>。</p>
]]></content>
    <category scheme="http://beforeload.github.io/tags/Memory/" term="Memory"/>
    <category scheme="http://beforeload.github.io/categories/Memory/" term="Memory"/>
  </entry>
</feed>
